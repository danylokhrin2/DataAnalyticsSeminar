{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populate Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from LLM.gpt import send_requestGPT\n",
    "from LLM.gemini import send_requestGemini\n",
    "from LLM.llama import send_requestLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count remaining Nan values in MASTER\n",
    "df = pd.read_csv(\"./data/result/MASTER.csv\")\n",
    "# print for each column ['gpt-4o-mini','gpt-4-0125-preview','gpt-3.5-turbo-0125','llama3.2-3b','llama3.1-8b','llama3-8b','gemini-1.5-flash',]]\n",
    "print(f\"Remaining Texts 'gpt-4o-mini' column: \\t\\t {df['gpt-4o-mini'].isnull().sum()} out of {len(df)}\")\n",
    "print(f\"Remaining Texts 'gpt-4-0125-preview' column: \\t {df['gpt-4-0125-preview'].isnull().sum()} out of {len(df)}\")\n",
    "print(f\"Remaining Texts 'gpt-3.5-turbo-0125' column: \\t {df['gpt-3.5-turbo-0125'].isnull().sum()} out of {len(df)}\")\n",
    "print(f\"Remaining Texts 'llama3.2-3b' column: \\t\\t {df['llama3.2-3b'].isnull().sum()} out of {len(df)}\")\n",
    "print(f\"Remaining Texts 'llama3.1-8b' column: \\t\\t {df['llama3.1-8b'].isnull().sum()} out of {len(df)}\")\n",
    "print(f\"Remaining Texts 'llama3-8b' column: \\t\\t {df['llama3-8b'].isnull().sum()} out of {len(df)}\")\n",
    "print(f\"Remaining Texts 'gemini-1.5-flash' column: \\t {df['gemini-1.5-flash'].isnull().sum()} out of {len(df)}\")\n",
    "\n",
    "# print total remaining \n",
    "print(f\"Total remaining texts: {df['gpt-4o-mini'].isnull().sum() + df['gpt-4-0125-preview'].isnull().sum() + df['gpt-3.5-turbo-0125'].isnull().sum() + df['llama3.2-3b'].isnull().sum() + df['llama3.1-8b'].isnull().sum() + df['llama3-8b'].isnull().sum() + df['gemini-1.5-flash'].isnull().sum()} out of {len(df)*7}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_row(model):\n",
    "    \n",
    "    df = pd.read_csv(\"./data/result/MASTER.csv\")\n",
    "    system_prompt = \"You are an assistant trained to identify if text contains sexism. Answer ONLY with '1' for Yes or '0' for No. ONLY CHECK FOR SEXISM AND NOT OTHER FORMS OF HATE SPEECH.\"\n",
    "    \n",
    "    nan_rows = df[df[model].isna()]\n",
    "\n",
    "    if not nan_rows.empty:\n",
    "        sequential_index = nan_rows.index[0]\n",
    "        text_value = df.at[sequential_index, 'text']\n",
    "        sexism = df.at[sequential_index, 'SEXISM']\n",
    "        if \"gemini\" in model:\n",
    "            try:\n",
    "                value = send_requestGemini(model, system_prompt, text_value)\n",
    "            except Exception as e:\n",
    "                if \"429\" not in str(e):\n",
    "                    value = -1\n",
    "                else:\n",
    "                    value = None\n",
    "        elif \"llama\" in model:\n",
    "            value = send_requestLlama(model, system_prompt, text_value)            \n",
    "        else:\n",
    "            value = send_requestGPT(model, system_prompt, text_value)\n",
    "        df.at[sequential_index, model] = value\n",
    "        print(f\"Populated NaN at index {sequential_index + 1} with value {value} vs. {sexism} for text: {text_value}\") \n",
    "    else:\n",
    "        print(f\"No NaN values found in {model} column.\")\n",
    "\n",
    "    df.to_csv(\"./data/result/MASTER.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMINI\n",
    "for i in range(500):\n",
    "    populate_row(\"gemini-1.5-flash\")\n",
    "    time.sleep(4) # to avoid rate limiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARALLELISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def populate_row_for_models(row):\n",
    "    system_prompt = \"You are an assistant trained to identify if text contains sexism. Answer ONLY with '1' for Yes or '0' for No. ONLY CHECK FOR SEXISM AND NOT OTHER FORMS OF HATE SPEECH.\"\n",
    "    \n",
    "    text_value = row['text']\n",
    "    \n",
    "    for model in ['gpt-4-0125-preview','gpt-3.5-turbo-0125','llama3.2-3b','llama3.1-8b','llama3-8b']:\n",
    "        if pd.isna(row[model]):\n",
    "            if \"gemini\" in model:\n",
    "                try:\n",
    "                  row[model] = send_requestGemini(model, system_prompt, text_value)\n",
    "                except:\n",
    "                  row[model] = -1\n",
    "            elif \"llama\" in model:\n",
    "                row[model] = send_requestLlama(model, system_prompt, text_value)\n",
    "            else:\n",
    "                row[model] = send_requestGPT(model, system_prompt, text_value)\n",
    "            \n",
    "    print(f\"Row {row['ID']} processed\")\n",
    "    \n",
    "    return row\n",
    "\n",
    "def populate_rows_in_parallel(max_rows):\n",
    "    df = pd.read_csv(\"./data/result/MASTER.csv\")\n",
    "\n",
    "    rows_with_nan = df[df[['gpt-4o-mini','gpt-4-0125-preview','gpt-3.5-turbo-0125','llama3.2-3b','llama3.1-8b','llama3-8b']].isna().any(axis=1)]\n",
    "    rows_with_nan = rows_with_nan.head(max_rows)\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        updated_rows = list(executor.map(populate_row_for_models, [row for _, row in rows_with_nan.iterrows()]))\n",
    "        \n",
    "    for updated_row in updated_rows:\n",
    "        df.loc[df['ID'] == updated_row['ID'], updated_row.index] = updated_row.values\n",
    "\n",
    "    df.to_csv(\"./data/result/MASTER.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    populate_rows_in_parallel(50)\n",
    "    print(f\"Processed {50*(i+1)} rows\")\n",
    "    time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
