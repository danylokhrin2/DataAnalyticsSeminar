Model,Accuracy,Precision,Recall,F1 Score,AUC
gpt-4o-mini,0.7430921052631579,0.2228081740276862,0.46879334257975036,0.30205540661304736,0.6243948052700954
gpt-4-0125-preview,0.8878289473684211,0.5352622061482821,0.4105409153952843,0.46467817896389324,0.6812921035270879
gpt-3.5-turbo-0125,0.32319078947368424,0.13785744771660263,0.8959778085991679,0.2389495098945811,0.5710529087780314
llama3.2-3b,0.796546052631579,0.17258883248730963,0.18862690707350901,0.1802518223989397,0.5334812087149593
llama3.1-8b,0.41694078947368424,0.1489308801591248,0.8307905686546463,0.25258275353152015,0.5960259990128989
llama3-8b,0.6146381578947369,0.19962962962962963,0.7475728155339806,0.31511254019292606,0.6721629705585559
